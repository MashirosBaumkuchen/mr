{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### time window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('../input/train_sample.csv')\n",
    "data['datetime'] = data['time'].apply(lambda x: str(x).split(' ')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(993712, 34)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rate 1\n",
    "posi_f = [\n",
    "    'voice_connection', 'wifi_connection',\n",
    "    'voice_convert_1', 'convert_rate',\n",
    "    'rrc_connection', 'erab_connection',\n",
    "    'esrvcc_convert'\n",
    "]\n",
    "\n",
    "# rate 0\n",
    "navg_f = [\n",
    "    'voice_disconnection', 'wifi_disconnection',\n",
    "    'wifi_disconnection_1',\n",
    "    'erab_trash', 'prb_pull', 'prb_push'\n",
    "]\n",
    "\n",
    "# count \n",
    "count_f = [\n",
    "    'voice_pull_delay','voice_count', 'data_count', \n",
    "    'rrc_max', 'csgb_rrc', 'rrc_2g', 'rrc_3g', 'rrc_num',\n",
    "    'voice_push_miss', 'voice_pull_miss'\n",
    "]\n",
    "\n",
    "# drop\n",
    "drop_f = [\n",
    "    'video_connection', 'video_disconnection', 'voice_convert_2', 'voice_convert_2', 'pdcch_cce'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_f = posi_f + navg_f + count_f\n",
    "\n",
    "cat_f = [\n",
    "    'ENODEB_ID', 'CID', 'hour'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_(dataframe, feature, fillna='0.0', astype=np.float32, normalize=True):\n",
    "    dataframe[feature] = dataframe[feature].fillna(fillna)\n",
    "    dataframe[feature] = dataframe[feature].astype(np.float32)\n",
    "    if normalize:\n",
    "        dataframe.loc[dataframe[feature]>1, feature] = 1\n",
    "        dataframe.loc[dataframe[feature]<0, feature] = 0\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "def normalized_feature(dataframe, feature):\n",
    "    mms = MinMaxScaler()\n",
    "    return mms.fit_transform(dataframe[feature].values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def creat_feature(dataframe, datetime):\n",
    "    tmp = dataframe[dataframe.loc[:,('datetime')]==datetime]\n",
    "    tmp = tmp.drop(['datetime'], axis=1)\n",
    "    \n",
    "    for feature in posi_f:\n",
    "        tmp = format_(tmp, feature, fillna=tmp[feature].mean())\n",
    "    for feature in navg_f:\n",
    "        tmp = format_(tmp, feature, fillna=tmp[feature].mean())\n",
    "    for feature in count_f:\n",
    "        tmp = format_(tmp, feature, fillna=tmp[feature].mean(), normalize=False)\n",
    "        tmp[feature] = normalized_feature(tmp, feature)\n",
    "    tmp = tmp.drop(drop_f, axis=1)\n",
    "\n",
    "    tmp.mr_low = tmp.mr_low.astype(np.float32)\n",
    "    tmp.mr_high = tmp.mr_high.astype(np.float32)\n",
    "    \n",
    "    # tmp['MCC'] = tmp['cgi'].apply(lambda x: str(x).split('-')[0])\n",
    "    # tmp['MNC'] = tmp['cgi'].apply(lambda x: str(x).split('-')[1])\n",
    "    tmp['ENODEB_ID'] = tmp['cgi'].apply(lambda x: str(x).split('-')[2])\n",
    "    tmp['CID'] = tmp['cgi'].apply(lambda x: str(x).split('-')[3])\n",
    "    tmp['ENODEB_ID'] = tmp['ENODEB_ID'].astype(np.int32)\n",
    "    tmp['CID'] = tmp['CID'].astype(np.int32)\n",
    "\n",
    "    # tmp['month'] = pd.to_datetime(tmp['time']).dt.month\n",
    "    # tmp['day'] = pd.to_datetime(tmp['time']).dt.day\n",
    "    tmp['hour'] = pd.to_datetime(tmp['time']).dt.hour\n",
    "\n",
    "    tmp = tmp.drop(['city', 'region', 'cgi', 'time'], axis=1)\n",
    "\n",
    "    return tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_valid = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(is_valid):\n",
    "    train = creat_feature(data, '2018-05-04')\n",
    "    train = pd.concat([train, creat_feature(data, '2018-05-03')])\n",
    "    train = pd.concat([train, creat_feature(data, '2018-05-02')])\n",
    "    train = pd.concat([train, creat_feature(data, '2018-05-01')])\n",
    "    train = pd.concat([train, creat_feature(data, '2018-04-30')])\n",
    "    test = creat_feature(data, '2018-05-05')\n",
    "else:\n",
    "    train = creat_feature(data, '2018-05-05')\n",
    "    train = pd.concat([train, creat_feature(data, '2018-05-04')])\n",
    "    train = pd.concat([train, creat_feature(data, '2018-05-03')])\n",
    "    train = pd.concat([train, creat_feature(data, '2018-05-02')])\n",
    "    train = pd.concat([train, creat_feature(data, '2018-05-01')])\n",
    "    test = creat_feature(data, '2018-05-06')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(709513, 28)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(142238, 28)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['voice_connection', 'wifi_connection', 'voice_disconnection',\n",
       "       'wifi_disconnection', 'esrvcc_convert', 'voice_convert_1',\n",
       "       'convert_rate', 'voice_push_miss', 'voice_pull_miss',\n",
       "       'voice_pull_delay', 'voice_count', 'data_count', 'rrc_connection',\n",
       "       'erab_connection', 'erab_trash', 'wifi_disconnection_1', 'prb_push',\n",
       "       'prb_pull', 'rrc_max', 'csgb_rrc', 'rrc_2g', 'rrc_3g', 'rrc_num',\n",
       "       'mr_low', 'mr_high', 'ENODEB_ID', 'CID', 'hour'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y1 = train['mr_low']\n",
    "train_y2 = train['mr_high']\n",
    "train_X = train.drop(['mr_low', 'mr_high'], axis=1)\n",
    "\n",
    "test_y1 = test['mr_low']\n",
    "test_y2 = test['mr_high']\n",
    "test_X = test.drop(['mr_low', 'mr_high'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {\n",
    "#     'application': 'binary',\n",
    "    'boosting': 'gbdt',\n",
    "    'num_leaves': 31,\n",
    "    'min_data_in_leaf': 100,\n",
    "    'learning_rate': 0.1,\n",
    "    'zero_as_missing': True,\n",
    "#     'lambda_l1': 1,\n",
    "    'lambda_l2': 1,\n",
    "    'metric':{'mse'}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ihave4cat/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py:1036: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "/home/ihave4cat/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py:681: UserWarning: categorical_feature in param dict is overridden.\n",
      "  warnings.warn('categorical_feature in param dict is overridden.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's l2: 0.00247395\n",
      "[100]\tvalid_0's l2: 0.00221246\n",
      "[150]\tvalid_0's l2: 0.00209973\n",
      "[200]\tvalid_0's l2: 0.00203727\n",
      "[250]\tvalid_0's l2: 0.0019903\n",
      "[300]\tvalid_0's l2: 0.00195721\n",
      "[350]\tvalid_0's l2: 0.00192989\n",
      "[400]\tvalid_0's l2: 0.00190916\n",
      "[450]\tvalid_0's l2: 0.00189284\n",
      "[500]\tvalid_0's l2: 0.00187536\n",
      "[550]\tvalid_0's l2: 0.00186614\n",
      "[600]\tvalid_0's l2: 0.00185409\n",
      "[650]\tvalid_0's l2: 0.0018436\n",
      "[700]\tvalid_0's l2: 0.00183476\n",
      "[750]\tvalid_0's l2: 0.00182689\n",
      "[800]\tvalid_0's l2: 0.00182098\n",
      "[850]\tvalid_0's l2: 0.00181453\n",
      "[900]\tvalid_0's l2: 0.00181007\n",
      "[950]\tvalid_0's l2: 0.00180497\n",
      "[1000]\tvalid_0's l2: 0.00179954\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[999]\tvalid_0's l2: 0.00179953\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's l2: 0.00236631\n",
      "[100]\tvalid_0's l2: 0.00212283\n",
      "[150]\tvalid_0's l2: 0.0020122\n",
      "[200]\tvalid_0's l2: 0.00194976\n",
      "[250]\tvalid_0's l2: 0.00190434\n",
      "[300]\tvalid_0's l2: 0.00187331\n",
      "[350]\tvalid_0's l2: 0.00185596\n",
      "[400]\tvalid_0's l2: 0.00183768\n",
      "[450]\tvalid_0's l2: 0.00181866\n",
      "[500]\tvalid_0's l2: 0.0018026\n",
      "[550]\tvalid_0's l2: 0.001791\n",
      "[600]\tvalid_0's l2: 0.00178\n",
      "[650]\tvalid_0's l2: 0.00177147\n",
      "[700]\tvalid_0's l2: 0.00176391\n",
      "[750]\tvalid_0's l2: 0.00175841\n",
      "[800]\tvalid_0's l2: 0.00174775\n",
      "[850]\tvalid_0's l2: 0.00174002\n",
      "[900]\tvalid_0's l2: 0.00173656\n",
      "[950]\tvalid_0's l2: 0.00172981\n",
      "[1000]\tvalid_0's l2: 0.00172583\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's l2: 0.00172583\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "X = train_X\n",
    "y = train_y1\n",
    "X_pred = test_X\n",
    "\n",
    "predictors = [i for i in X.columns]\n",
    "stacking_num = 2\n",
    "bagging_num = 3\n",
    "bagging_test_size = 0.33\n",
    "num_boost_round = 500\n",
    "early_stopping_rounds = 100\n",
    "\n",
    "stacking_model=[]\n",
    "bagging_model=[]\n",
    "\n",
    "l2_error = []\n",
    "#     X = X.values\n",
    "#     y = y.values\n",
    "layer_train = np.zeros((X.shape[0],2))\n",
    "\n",
    "leng = X.shape[0]\n",
    "\n",
    "for i in range(2):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=i)\n",
    "\n",
    "    lgb_train = lgb.Dataset(X_train, y_train, categorical_feature=cat_f)\n",
    "    lgb_eval = lgb.Dataset(X_test, y_test, categorical_feature=cat_f)\n",
    "\n",
    "    gbm=lgb.train(param,\n",
    "                  lgb_train,\n",
    "                  num_boost_round=1000,\n",
    "                  valid_sets=lgb_eval,\n",
    "                  verbose_eval=50,\n",
    "                  early_stopping_rounds=100)\n",
    "    stacking_model.append(gbm)\n",
    "X = np.hstack((X,layer_train[:,1].reshape((-1,1))))\n",
    "\n",
    "predictors.append('lgb_result')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's l2: 0.00247073\n",
      "[100]\tvalid_0's l2: 0.0022387\n",
      "[150]\tvalid_0's l2: 0.00212993\n",
      "[200]\tvalid_0's l2: 0.00206864\n",
      "[250]\tvalid_0's l2: 0.002033\n",
      "[300]\tvalid_0's l2: 0.00199866\n",
      "[350]\tvalid_0's l2: 0.00197352\n",
      "[400]\tvalid_0's l2: 0.00195466\n",
      "[450]\tvalid_0's l2: 0.00194066\n",
      "[500]\tvalid_0's l2: 0.00192701\n",
      "[550]\tvalid_0's l2: 0.00191546\n",
      "[600]\tvalid_0's l2: 0.00190673\n",
      "[650]\tvalid_0's l2: 0.00190036\n",
      "[700]\tvalid_0's l2: 0.0018906\n",
      "[750]\tvalid_0's l2: 0.001881\n",
      "[800]\tvalid_0's l2: 0.00187474\n",
      "[850]\tvalid_0's l2: 0.00186605\n",
      "[900]\tvalid_0's l2: 0.00186182\n",
      "[950]\tvalid_0's l2: 0.00185751\n",
      "[1000]\tvalid_0's l2: 0.00185428\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[994]\tvalid_0's l2: 0.00185392\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's l2: 0.00238717\n",
      "[100]\tvalid_0's l2: 0.00215039\n",
      "[150]\tvalid_0's l2: 0.00204213\n",
      "[200]\tvalid_0's l2: 0.00197869\n",
      "[250]\tvalid_0's l2: 0.00193465\n",
      "[300]\tvalid_0's l2: 0.00190052\n",
      "[350]\tvalid_0's l2: 0.00187813\n",
      "[400]\tvalid_0's l2: 0.00186003\n",
      "[450]\tvalid_0's l2: 0.00184667\n",
      "[500]\tvalid_0's l2: 0.00183343\n",
      "[550]\tvalid_0's l2: 0.00182142\n",
      "[600]\tvalid_0's l2: 0.00180992\n",
      "[650]\tvalid_0's l2: 0.00179984\n",
      "[700]\tvalid_0's l2: 0.00179286\n",
      "[750]\tvalid_0's l2: 0.00178665\n",
      "[800]\tvalid_0's l2: 0.00177881\n",
      "[850]\tvalid_0's l2: 0.00177258\n",
      "[900]\tvalid_0's l2: 0.00176343\n",
      "[950]\tvalid_0's l2: 0.00175822\n",
      "[1000]\tvalid_0's l2: 0.00175525\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[991]\tvalid_0's l2: 0.00175504\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's l2: 0.00246071\n",
      "[100]\tvalid_0's l2: 0.00220612\n",
      "[150]\tvalid_0's l2: 0.00208606\n",
      "[200]\tvalid_0's l2: 0.00202184\n",
      "[250]\tvalid_0's l2: 0.00197633\n",
      "[300]\tvalid_0's l2: 0.00194329\n",
      "[350]\tvalid_0's l2: 0.00191498\n",
      "[400]\tvalid_0's l2: 0.00190038\n",
      "[450]\tvalid_0's l2: 0.00188328\n",
      "[500]\tvalid_0's l2: 0.00187385\n",
      "[550]\tvalid_0's l2: 0.00186454\n",
      "[600]\tvalid_0's l2: 0.00185501\n",
      "[650]\tvalid_0's l2: 0.00184623\n",
      "[700]\tvalid_0's l2: 0.00183831\n",
      "[750]\tvalid_0's l2: 0.00183283\n",
      "[800]\tvalid_0's l2: 0.00182949\n",
      "[850]\tvalid_0's l2: 0.00182508\n",
      "[900]\tvalid_0's l2: 0.00182325\n",
      "[950]\tvalid_0's l2: 0.00182122\n",
      "[1000]\tvalid_0's l2: 0.00182017\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's l2: 0.00182017\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ENODEB_ID               11126\n",
       "CID                      4554\n",
       "hour                     3270\n",
       "data_count               1911\n",
       "prb_push                 1564\n",
       "rrc_max                  1318\n",
       "rrc_num                   760\n",
       "rrc_2g                    689\n",
       "prb_pull                  650\n",
       "rrc_3g                    556\n",
       "csgb_rrc                  449\n",
       "esrvcc_convert            407\n",
       "voice_pull_delay          387\n",
       "voice_disconnection       345\n",
       "voice_count               321\n",
       "voice_push_miss           305\n",
       "convert_rate              261\n",
       "voice_pull_miss           249\n",
       "voice_connection          173\n",
       "voice_convert_1           136\n",
       "wifi_disconnection        131\n",
       "wifi_disconnection_1      124\n",
       "wifi_connection           107\n",
       "rrc_connection             97\n",
       "erab_trash                 61\n",
       "erab_connection            49\n",
       "lgb_result                  0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for bn in range(bagging_num):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=bagging_test_size, random_state=bn)\n",
    "\n",
    "    lgb_train = lgb.Dataset(X_train, y_train)\n",
    "    lgb_eval = lgb.Dataset(X_test, y_test)\n",
    "\n",
    "    gbm = lgb.train(param,\n",
    "                    lgb_train,\n",
    "                    num_boost_round=1000,\n",
    "                    valid_sets=lgb_eval,\n",
    "                    verbose_eval=50,\n",
    "                    early_stopping_rounds=100)\n",
    "    bagging_model.append(gbm)\n",
    "    l2_error.append(mean_squared_error(gbm.predict(X_test,num_iteration=gbm.best_iteration),y_test))\n",
    "\n",
    "    feat_imp = pd.Series(gbm.feature_importance(), predictors).sort_values(ascending=False)\n",
    "\n",
    "test_pred = np.zeros((X_pred.shape[0],stacking_num))\n",
    "for sn,gbm in enumerate(stacking_model):\n",
    "    pred = gbm.predict(X_pred,num_iteration=gbm.best_iteration)\n",
    "    test_pred[:,sn] = pred\n",
    "\n",
    "    X_pred = np.hstack((X_pred,test_pred.mean(axis=1).reshape((-1,1))))\n",
    "\n",
    "for bn,gbm in enumerate(bagging_model):\n",
    "    pred = gbm.predict(X_pred,num_iteration=gbm.best_iteration)\n",
    "    if bn==0:\n",
    "        pred_out = pred\n",
    "    else:\n",
    "        pred_out += pred\n",
    "pre =  pred_out/bagging_num\n",
    "feat_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0048865344900011\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "valid_auc = metrics.mean_squared_error(test_y1, pre)\n",
    "print(valid_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: pre is 0.011593, real is 0.016421\n",
      "1: pre is 0.012188, real is 0.014527\n",
      "2: pre is 0.008377, real is 0.015449\n",
      "3: pre is 0.012789, real is 0.002716\n",
      "4: pre is 0.013199, real is 0.003485\n",
      "5: pre is 0.025471, real is 0.020363\n",
      "6: pre is 0.014480, real is 0.021670\n",
      "7: pre is 0.011590, real is 0.011759\n",
      "8: pre is 0.008197, real is 0.018023\n",
      "9: pre is 0.004469, real is 0.011229\n",
      "10: pre is 0.010250, real is 0.003256\n",
      "11: pre is 0.009554, real is 0.014210\n",
      "12: pre is 0.005104, real is 0.014879\n",
      "13: pre is 0.003922, real is 0.011437\n",
      "14: pre is 0.010217, real is 0.017893\n",
      "15: pre is 0.010289, real is 0.004284\n",
      "16: pre is 0.014769, real is 0.033241\n",
      "17: pre is 0.011881, real is 0.016056\n",
      "18: pre is 0.011121, real is 0.017123\n",
      "19: pre is 0.007400, real is 0.015262\n",
      "20: pre is 0.010635, real is 0.003278\n",
      "21: pre is 0.005849, real is 0.006410\n",
      "22: pre is 0.009905, real is 0.010714\n",
      "23: pre is 0.013752, real is 0.003889\n",
      "24: pre is 0.095254, real is 0.061535\n",
      "25: pre is 0.096256, real is 0.038024\n",
      "26: pre is 0.121034, real is 0.047875\n",
      "27: pre is 0.088457, real is 0.024491\n",
      "28: pre is 0.087596, real is 0.059927\n",
      "29: pre is 0.108538, real is 0.032010\n",
      "30: pre is 0.093648, real is 0.015788\n",
      "31: pre is 0.100749, real is 0.018952\n",
      "32: pre is 0.107452, real is 0.031669\n",
      "33: pre is 0.098180, real is 0.029443\n",
      "34: pre is 0.225509, real is 0.134630\n",
      "35: pre is 0.199146, real is 0.212941\n",
      "36: pre is 0.246976, real is 0.145389\n",
      "37: pre is 0.164306, real is 0.212069\n",
      "38: pre is 0.191156, real is 0.054720\n",
      "39: pre is 0.076241, real is 0.042056\n",
      "40: pre is 0.150631, real is 0.058679\n",
      "41: pre is 0.204160, real is 0.240947\n",
      "42: pre is 0.135291, real is 0.147685\n",
      "43: pre is 0.112384, real is 0.069299\n",
      "44: pre is 0.244223, real is 0.118152\n",
      "45: pre is 0.107360, real is 0.063085\n",
      "46: pre is 0.089452, real is 0.065401\n",
      "47: pre is 0.159255, real is 0.128595\n",
      "48: pre is 0.418941, real is 0.041451\n",
      "49: pre is 0.392989, real is 0.137915\n",
      "50: pre is 0.385527, real is 0.108088\n",
      "51: pre is 0.454570, real is 0.009381\n",
      "52: pre is 0.306592, real is 0.051724\n",
      "53: pre is 0.488199, real is 0.249235\n",
      "54: pre is 0.450849, real is 0.287944\n",
      "55: pre is 0.491540, real is 0.094891\n",
      "56: pre is 0.448570, real is 0.222862\n",
      "57: pre is 0.366484, real is 0.162876\n",
      "58: pre is 0.420511, real is 0.053628\n",
      "59: pre is 0.363363, real is 0.151005\n",
      "60: pre is 0.458107, real is 0.090405\n",
      "61: pre is 0.398573, real is 0.350000\n",
      "62: pre is 0.382151, real is 0.080702\n",
      "63: pre is 0.448957, real is 0.148462\n",
      "64: pre is 0.382851, real is 0.135714\n",
      "65: pre is 0.410751, real is 0.148225\n",
      "66: pre is 0.411706, real is 0.507625\n",
      "67: pre is 0.362309, real is 0.083933\n",
      "68: pre is 0.434853, real is 0.568233\n",
      "69: pre is 0.418248, real is 0.381153\n",
      "70: pre is 0.392901, real is 0.541069\n",
      "71: pre is 0.410206, real is 0.046584\n",
      "72: pre is 0.066008, real is 0.042161\n",
      "73: pre is 0.114010, real is 0.055586\n",
      "74: pre is 0.059652, real is 0.034651\n",
      "75: pre is 0.059500, real is 0.022866\n",
      "76: pre is 0.065254, real is 0.033734\n",
      "77: pre is 0.069370, real is 0.024721\n",
      "78: pre is 0.084905, real is 0.026452\n",
      "79: pre is 0.088862, real is 0.037671\n",
      "80: pre is 0.077407, real is 0.032810\n",
      "81: pre is 0.088503, real is 0.032700\n",
      "82: pre is 0.250713, real is 0.158342\n",
      "83: pre is 0.176482, real is 0.117616\n",
      "84: pre is 0.098093, real is 0.057395\n",
      "85: pre is 0.065667, real is 0.020019\n",
      "86: pre is 0.087987, real is 0.050269\n",
      "87: pre is 0.097940, real is 0.037465\n",
      "88: pre is 0.240063, real is 0.170885\n",
      "89: pre is 0.074476, real is 0.052338\n",
      "90: pre is 0.052577, real is 0.025448\n",
      "91: pre is 0.239537, real is 0.098733\n",
      "92: pre is 0.206166, real is 0.093972\n",
      "93: pre is 0.217550, real is 0.104150\n",
      "94: pre is 0.220802, real is 0.148300\n",
      "95: pre is 0.154750, real is 0.065768\n",
      "96: pre is 0.004590, real is 0.006032\n",
      "97: pre is 0.006472, real is 0.003411\n",
      "98: pre is 0.009301, real is 0.000000\n",
      "99: pre is 0.005295, real is 0.000226\n",
      "100: pre is 0.019691, real is 0.001821\n",
      "101: pre is 0.008490, real is 0.000552\n",
      "102: pre is 0.012619, real is 0.000000\n",
      "103: pre is 0.023387, real is 0.000000\n",
      "104: pre is 0.007962, real is 0.000000\n",
      "105: pre is 0.006623, real is 0.000143\n",
      "106: pre is 0.006518, real is 0.000000\n",
      "107: pre is 0.012701, real is 0.013355\n",
      "108: pre is 0.009595, real is 0.004054\n",
      "109: pre is 0.006009, real is 0.001026\n",
      "110: pre is 0.004297, real is 0.001711\n",
      "111: pre is 0.017198, real is 0.000000\n",
      "112: pre is 0.008776, real is 0.000190\n",
      "113: pre is 0.008027, real is 0.009124\n",
      "114: pre is 0.029329, real is 0.000000\n",
      "115: pre is 0.005437, real is 0.005784\n",
      "116: pre is 0.007489, real is 0.003299\n",
      "117: pre is 0.003654, real is 0.000620\n",
      "118: pre is 0.006227, real is 0.000000\n",
      "119: pre is 0.007948, real is 0.000000\n",
      "120: pre is 0.002389, real is 0.005694\n",
      "121: pre is -0.000535, real is 0.001057\n",
      "122: pre is 0.000903, real is 0.002780\n",
      "123: pre is -0.005522, real is 0.002935\n",
      "124: pre is 0.014534, real is 0.004325\n",
      "125: pre is -0.005125, real is 0.001702\n",
      "126: pre is -0.002019, real is 0.003362\n",
      "127: pre is 0.002368, real is 0.002911\n",
      "128: pre is -0.004579, real is 0.002776\n",
      "129: pre is -0.007578, real is 0.001583\n",
      "130: pre is -0.002175, real is 0.001422\n",
      "131: pre is 0.009277, real is 0.001790\n",
      "132: pre is 0.012713, real is 0.000000\n",
      "133: pre is 0.001513, real is 0.004228\n",
      "134: pre is -0.003849, real is 0.000633\n",
      "135: pre is 0.008752, real is 0.001585\n",
      "136: pre is -0.001926, real is 0.006786\n",
      "137: pre is -0.002236, real is 0.001274\n",
      "138: pre is 0.004863, real is 0.000000\n",
      "139: pre is -0.006538, real is 0.004498\n",
      "140: pre is 0.000475, real is 0.003961\n",
      "141: pre is 0.001305, real is 0.012283\n",
      "142: pre is -0.006309, real is 0.003303\n",
      "143: pre is 0.011697, real is 0.000098\n",
      "144: pre is 0.039188, real is 0.028239\n",
      "145: pre is 0.021200, real is 0.006421\n",
      "146: pre is 0.007418, real is 0.012227\n",
      "147: pre is 0.012963, real is 0.036271\n",
      "148: pre is 0.031646, real is 0.019747\n",
      "149: pre is 0.013474, real is 0.020677\n",
      "150: pre is 0.056865, real is 0.074766\n",
      "151: pre is 0.051054, real is 0.107143\n",
      "152: pre is 0.017306, real is 0.007816\n",
      "153: pre is 0.030658, real is 0.025926\n",
      "154: pre is 0.010320, real is 0.018137\n",
      "155: pre is 0.027788, real is 0.068929\n",
      "156: pre is 0.034480, real is 0.037140\n",
      "157: pre is 0.069436, real is 0.364807\n",
      "158: pre is 0.010070, real is 0.016850\n",
      "159: pre is 0.017194, real is 0.022215\n",
      "160: pre is 0.029468, real is 0.046077\n",
      "161: pre is 0.054077, real is 0.141732\n",
      "162: pre is 0.016556, real is 0.020386\n",
      "163: pre is 0.020178, real is 0.051525\n",
      "164: pre is 0.030567, real is 0.014868\n",
      "165: pre is 0.027030, real is 0.003155\n",
      "166: pre is 0.032252, real is 0.027336\n",
      "167: pre is 0.013285, real is 0.008512\n",
      "168: pre is 0.157204, real is 0.156434\n",
      "169: pre is 0.167088, real is 0.134707\n",
      "170: pre is 0.179430, real is 0.125398\n",
      "171: pre is 0.144745, real is 0.136457\n",
      "172: pre is 0.175687, real is 0.122726\n",
      "173: pre is 0.214270, real is 0.110142\n",
      "174: pre is 0.125178, real is 0.116057\n",
      "175: pre is 0.163818, real is 0.133781\n",
      "176: pre is 0.186564, real is 0.126165\n",
      "177: pre is 0.157958, real is 0.130451\n",
      "178: pre is 0.159060, real is 0.157769\n",
      "179: pre is 0.138441, real is 0.151748\n",
      "180: pre is 0.196139, real is 0.151223\n",
      "181: pre is 0.158896, real is 0.144812\n",
      "182: pre is 0.154451, real is 0.117391\n",
      "183: pre is 0.149625, real is 0.150107\n",
      "184: pre is 0.161102, real is 0.136062\n",
      "185: pre is 0.159395, real is 0.122985\n",
      "186: pre is 0.145859, real is 0.122849\n",
      "187: pre is 0.158842, real is 0.121007\n",
      "188: pre is 0.174956, real is 0.108814\n",
      "189: pre is 0.151497, real is 0.205295\n",
      "190: pre is 0.152183, real is 0.113189\n",
      "191: pre is 0.152878, real is 0.112737\n",
      "192: pre is 0.131427, real is 0.093418\n",
      "193: pre is 0.075629, real is 0.030277\n",
      "194: pre is 0.075583, real is 0.033405\n",
      "195: pre is 0.085775, real is 0.031444\n",
      "196: pre is 0.088857, real is 0.035069\n",
      "197: pre is 0.083772, real is 0.082495\n",
      "198: pre is 0.073938, real is 0.050538\n",
      "199: pre is 0.127319, real is 0.057729\n",
      "200: pre is 0.101815, real is 0.075688\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(pre)):\n",
    "    if i>200: break\n",
    "    print('%d: pre is %f, real is %f' % (i, pre[i], test_y1.tolist()[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
